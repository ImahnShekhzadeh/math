\section{Measure Theory}
\begin{defn}[Generated $\sigma$-algebra \cite{generated-sigma-algebras}]
	Let $X$ be a set and $\mathcal E\subset \mathcal P(X)$ a non-empty collection of subsets of $X$. The \textit{smallest} $\sigma$-algebra containing all the sets of $\mathcal E$ is denoted by $\sigma(\mathcal E)$. 
\end{defn}

\begin{corollary}
	Let $\mathcal E_1$, $\mathcal E_2\subset \mathcal P(X)$ be such that $\mathcal E_1 \subset \mathcal E_2$. Then $\sigma(\mathcal E_1) \subset \sigma(\mathcal E_2)$.    
\end{corollary}

\begin{defn}[Measurable function]
	Let $(X, \mathcal E)$ and $(Y, \mathcal F)$ be measurable spaces. A map $f: X\rightarrow Y$ is said to be \textit{$\mathcal E$-measurable} if 
	\begin{align} \label{measurable-mapping-eq}
		f^{-1}(\mathcal F) := \left\{ f^{-1}(A) \vert A\in \mathcal F \right\} := \left\{ \left\{ x\in X \vert f(x) \in A \right\} \vert A\in \mathcal F \right\} \subset \mathcal E.
	\end{align} 
\end{defn}

\begin{theorem}[Generator and measurable function \cite{measurable-functions}] \label{generator-and-measurable-function} Let $(X, \mathcal E)$ and $(Y, \mathcal F)$ be measurable spaces and $\mathcal F = \sigma(\mathcal G)$, i.e. $\mathcal F$ is the $\sigma$-algebra generated by a family $\mathcal G \subset \mathcal P(Y)$, where $\mathcal P(Y)$ denotes the power set of $Y$. Then $f: X\rightarrow Y$ is measurable if and only if 
	\begin{align}
		f^{-1}\left(G\right) \in \mathcal E \ \forall G\in\mathcal G. 
	\end{align}
\end{theorem}

\begin{proof}
	\enquote{$\Rightarrow$} Since $\mathcal F = \sigma(\mathcal G)$, it obviously holds that $\mathcal G\subset \mathcal F$ and therefore $f^{-1}(G)\in \mathcal E \ \forall G\in\mathcal G$ is ensured by $f$ being measurable. 
	\\ \\ 
	\enquote{$\Leftarrow$} Define the set $\mathcal M:= \left\{ B\subset Y \mid f^{-1}(B)\in \mathcal A \right\}$. First we want to convince ourselves that $\mathcal M$ is a $\sigma$-algebra on $Y$. 
	\begin{enumerate}
		\item $\emptyset \in \mathcal M$, since $f^{-1}(\emptyset) = \left\{ x\in X \mid f(x)\in \emptyset \right\} = \emptyset$. 
		
		\item Let $B\in \mathcal M$, then also $Y\backslash B\in \mathcal M$, since $f^{-1}\left(Y\backslash B\right) = f^{-1}(Y)\backslash f^{-1}(B)$, as can be easily shown by using the definition of the complement of a set. Since $f^{-1}(Y) = X$, it follows that $f^{-1}(Y\backslash B) = X\backslash f^{-1}(B)$. Since by assumption $B\in \mathcal M$ (and therefore $f^{-1}(B)\in \mathcal A$) and $\mathcal A$ itself is a $\sigma$-algebra, it follows that $X\backslash f^{-1}(B)\in\mathcal A$. 
		
		\item  Let $B_i \in \mathcal M$ for $i\in \mathbb N$, then also $\cup_{i\in\mathbb N}B_i\in \mathcal M$, since $$f^{-1}\left(\bigcup_{i\in\mathbb N}B_i\right) = \bigcup_{i\in\mathbb N}f^{-1}\left(B_i\right).$$ 
	\end{enumerate}
	Since $\mathcal M$ is a $\sigma$-algebra and since $\mathcal G\subset \mathcal M \Rightarrow \mathcal F = \sigma(\mathcal G)\subset \mathcal M = \sigma(\mathcal M) $, it follows that $f$ is measurable. 
\end{proof}

\begin{lemma}[Push-forward measure]\label{push-forward-measure}
	Let $(X, \mathcal E)$ and $(Y, \mathcal F)$ be measurable spaces. Given a measurable map $f: X\rightarrow Y$ and a measure $\mu$ on $\mathcal E$, let $f_{\#}\mu$ be defined by 
	\begin{align}
		f_{\#}\mu(A) := \mu(f^{-1}(A)) \quad \forall A\in \mathcal F. 
	\end{align}
	$f_{\#}\mu$ is a measure on $\mathcal F$ and called the \textit{push-forward} of $\mu$ under $f$. 
\end{lemma}

\begin{proof}
	Obviously, $f_{\#}\mu(\emptyset) = \mu(f^{-1}(\emptyset)) \overset{\footnotesize\eqref{measurable-mapping-eq}}{=} \mu(\emptyset) = 0$. Also, no matter what kind of set $A\in \mathcal F$ we take, since $\mu(A) \geq 0$, the same holds for $f_{\#}\mu(A)$. Finally, let $(A_n)_{n\in\mathbb{N}} \subset \mathcal F$ be a sequence of mutually disjoint sets, then: 
	\begin{align*}
		f_{\#}\mu\left(\bigcup_{n\in\mathbb N}A_n \right) &= 
		\mu\left(f^{-1}\left(\bigcup_{n\in\mathbb N}A_n\right) \right) \overset{\tiny\eqref{measurable-mapping-eq}}{=}
		\mu\left( \left\{ x\in X \bigg\vert f(x) \in  \bigcup_{n\in\mathbb N}A_n \right\}\right) 
		\\ &= 		
		\mu\left( \bigcup_{n\in\mathbb N}\left\{ x\in X \vert f(x)\in A_n \right\} \right) 
		=
		\mu\left( \bigcup_{n\in\mathbb{N}}f^{-1}(A_n) \right)
		\\ &= \sum_{n\in\mathbb N}\mu\left(f^{-1}(A_n)\right) = \sum_{n\in\mathbb{N}}f_{\#}\mu(A_n) 
	\end{align*}
\end{proof}

\begin{corollary}[Push-forward of a probability measure]
	Let $(X, \mathcal E)$ and $(Y, \mathcal F)$	be measurable spaces. Given a measurable map $f: X\rightarrow Y$ and a \underline{probability} measure on $\mathcal E$, the push-forward of $\mu$ under $f$, denoted by $f_{\#}\mu$, is also a probability measure. 
\end{corollary}

\begin{proof}
	Since $\mu$ is in particular a measure and thus $f_{\#}\mu$ is also a measure, we only need to show that  
	\begin{align}
		f_{\#}\mu(Y) = \mu\left(f^{-1}\left(\mu\right)\right) = \mu\left(\left\{ x\in X \mid f(x)\in Y  \right\}\right) = \mu(X) = 1. 
	\end{align}
\end{proof} 

\begin{defn}[$\sigma$-finite measure] Let $(X, \mathcal A)$ be a measurable space and $\mu$ a measure on it. If there are sets $A_1$, $A_2$, $\dots \in \mathcal A$ with $\mu(A_n) < \infty \ \forall n\in \mathbb N$ that satisfy 
	\begin{align}
		\bigcup_{n\in\mathbb N}A_n = X
	\end{align}  
	then we say $\mu$ is \textit{$\sigma$-finite}. 
\end{defn}

\begin{remark}
	Obviously, every finite measure is $\sigma$-finite; however, the converse does not necessarily hold \cite{sigma-finite}. 
\end{remark}


\begin{defn}[Absolutely continuous measures.] 
	Let $\mu$ and $\nu$ be two measures on a $\sigma$-algebra $\mathcal A$. $\nu$ is called \textit{absolutely continuous} w.r.t. $\mu$, written as 
	\begin{align}
		\nu \ll \mu, 
	\end{align}
	if for each $A\in \mathcal A$, $\mu(A) = 0$ implies $\nu(A) = 0$. If $\mu$ and $\nu$ are both absolutely continuous w.r.t each other $\mu$ and $\nu$ are called \textit{equivalent}. 
\end{defn}

\begin{theorem}[Radon-Nikodym Theorem \cite{measure-integration}]
	Let $\mu$ be a $\sigma$-finite measure on a measurable space ($S$, $\mathcal{A}$). Then it is equivalent: 
	\begin{enumerate}
		\item $\nu \ll \mu$, 
		\item $d\nu = hd\mu$ for some measurable function $h: S\rightarrow \mathbb R_{+}$. 
	\end{enumerate}
	The density $h$ then is $\mu$-a.e. finite and $\mu$-a.e. unique. 
\end{theorem}

\begin{lemma}[Frechét Inception Distance]
	For two multivariate Gaussian distributions $\mathcal G(\mu_{x}, \Sigma_{x})$, $\mathcal G(\mu_{y}, \Sigma_{y})$, the \textit{Frechét Inception Distance} (FID) is defined as [\url{https://arxiv.org/pdf/1706.08500.pdf}]: 
	\begin{align}
		d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{y}, \Sigma_{y})\right) := \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y} \right\vert\right\vert_{2}^{2} + \text{Tr}\left(\Sigma_{x} + \Sigma_{y} - 2\left(\Sigma_{x}\Sigma_{y}\right)^{\frac{1}{2}}\right)}. 
	\end{align}
	It is a metric.\
\end{lemma}
\begin{proof}
	Clearly, $d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{x}, \Sigma_{x})\right) = 0$.\ Also, $$d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{y}, \Sigma_{y})\right) = d\left(\mathcal G(\mu_{y}, \Sigma_{y}), \mathcal G(\mu_{x}, \Sigma_{x})\right),$$ which holds because $\text{Tr}(AB) = \text{Tr}(BA)$ for any matrices $A$ and $B$.\ To see that $$d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{y}, \Sigma_{y})\right) \geq 0,$$ note that $\text{Tr}(\Sigma_{x} + \Sigma_{y} - 2\left(\Sigma_{x}\Sigma_{y}\right)^{1/2}) = \text{Tr}\left(\left(\Sigma_{x}^{1/2} - \Sigma_{y}^{1/2}\right)^{2}\right) \geq 0$, since the covariance matrices contain the variances on the diagonal, which are obviously non-negative.\ It now remains to be shown that also the triangle inequality is fulfilled.\ For this, note that 
	\begin{align}
		d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{y}, \Sigma_{y})\right) &= \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y} \right\vert\right\vert_{2}^{2} + \text{Tr}\left(\Sigma_{x} + \Sigma_{y} - 2\left(\Sigma_{x}\Sigma_{y}\right)^{\frac{1}{2}}\right)} 
		\\ &= \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y} \right\vert\right\vert_{2}^{2} + \text{Tr}\left(\left(\Sigma_{x}^{1/2} - \Sigma_{y}^{1/2}\right)^{2}\right)}
		\\ &= \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y} \right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{x} - \sigma_{y}\right\vert\right\vert_{2}^{2}}, 
	\end{align}
	where $\sigma_{x}$ and $\sigma_{y}$ denote vectors containing the standard deviations of the two Gaussian distributions.\ Clearly, 
	\begin{align}
		d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{z}, \Sigma_{z})\right) &= \sqrt{\left\vert\left\vert \mu_{x} - \mu_{z} \right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{x} - \sigma_{z}\right\vert\right\vert_{2}^{2}} 
		\\ &\leq \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y}\right\vert\right\vert_{2}^{2} + \left\vert\left\vert \mu_{y} - \mu_{z}\right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{x} - \sigma_{y}\right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{y} - \sigma_{z}\right\vert\right\vert_{2}^{2}} 
		\\ &\leq \sqrt{\left\vert\left\vert \mu_{x} - \mu_{y}\right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{x} - \sigma_{y}\right\vert\right\vert_{2}^{2}} \ + \ \sqrt{\left\vert\left\vert \mu_{y} - \mu_{z}\right\vert\right\vert_{2}^{2} + \left\vert\left\vert \sigma_{y} - \sigma_{z}\right\vert\right\vert_{2}^{2}} 
		\\ &= d\left(\mathcal G(\mu_{x}, \Sigma_{x}), \mathcal G(\mu_{y}, \Sigma_{y})\right) + d\left(\mathcal G(\mu_{y}, \Sigma_{y}), \mathcal G(\mu_{z}, \Sigma_{z})\right), 
	\end{align}
	since $\sqrt{x+y} \leq \sqrt{x} + \sqrt{y}$, as one can directly show by squaring for non-negative $x$, $y\in\mathbb R$.\ 
\end{proof}

\begin{defn}[Convergence in probability]
	Assume we have a sequence of random variables $(X_{n})_{n\in \mathbb N}$, defined on a probability space $(\Omega, \mathcal F, \mathbb P)$.\ We say this sequence converges to another random variable $X$ if 
	\begin{align}
		\forall \epsilon > 0: \lim\limits_{n\rightarrow\infty}\mathbb P\left\{ \left\vert X_{n} - X\right\vert > \epsilon \right\} = 0. 
	\end{align}
\end{defn}